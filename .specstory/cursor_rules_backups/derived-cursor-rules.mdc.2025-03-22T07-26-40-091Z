
## PROJECT OVERVIEW

This project aims to create a lesson management system integrated with AI-powered transcription and summarization features.  The system will allow users to upload audio recordings of lessons, generate summaries and tags, and manage their lesson schedules.  Version updates will be noted in the relevant sections.  OpenAI Whisper API and Google Gemini API are used for transcription and summarization. Google Gemini API was added to the tech stack. Node.js 18 runtime will be deprecated on 2025-04-30 and decommissioned on 2025-10-31.  Consider upgrading to Node.js 20 to avoid disruption.  The maximum audio duration for transcription is 90 minutes. For files larger than 25MB, implement a process to split the audio into smaller chunks before sending to the Whisper API. For files larger than 30MB, a warning will be displayed if not on Wi-Fi. The maximum file size for audio uploads is 100MB and the maximum audio duration is 90 minutes. A warning will be displayed to the user if they are attempting to upload a file larger than 30MB over a non-Wi-Fi network.  All functions must be deployed to the `asia-northeast1` region. Implement a mechanism to handle large files gracefully, providing warnings to the users when necessary.  Implement robust error handling and logging for all API calls. Implement retry mechanisms for failed API calls with exponential backoff. Lesson data includes `instrument`, `summary`, `tags`, `summaryRequired`, `summaryInProgress`, `transcriptionCompleteTime`, `transcriptionId`, `processingId`, and `lockAcquiredAt` fields. `instrument` is populated from user profile. The `generateSummaryFromTranscriptionV2` function will only generate a summary if the `summaryRequired` field is `true` and the lesson's status is `transcribed`.  A new `transcriptionId` field has been added to the Lesson data structure to prevent duplicate processing. A new `transcriptionCompleteTime` field has been added to the Lesson data structure.  A new `lockAcquiredAt` field has been added to the Lesson data structure. Dify input field settings for transcription (callDifyAPI function) are no longer needed since Dify has been removed. Dify input field settings for summary and tag generation (createLessonSummary function) are no longer needed since Dify has been removed. To check OpenAI API errors, follow these steps: 1. Set the OPENAI_API_KEY environment variable in your Firebase Functions environment. 2. Redeploy your functions to apply the new settings. 3. Check the Firebase Functions logs to monitor function executions and identify errors.  For detailed API request/response logs, check the browser's DevTools console.  The Whisper API has a file upload limit; files exceeding this limit will result in a "413 Request Entity Too Large" error. User only receives summary and tags; transcription is not provided. A mechanism to handle large files gracefully, providing warnings to users when necessary, has been implemented. Robust error handling and logging for all API calls have been implemented. Retry mechanisms for failed API calls with exponential backoff have been implemented. The maximum file size for audio uploads is 100MB, and the maximum audio duration is 90 minutes. A warning will be displayed to the user if they are attempting to upload a file larger than 30MB over a non-Wi-Fi network. All functions must be deployed to the `asia-northeast1` region. The `sys.app_id` parameter is required for Dify API requests. This parameter is no longer needed since Dify has been removed. All functions should be deployed to the `asia-northeast1` region.  All functions should be deployed to the asia-northeast1 region.  The maximum file size for audio uploads is 100MB, and the maximum audio duration is 90 minutes. A warning will be displayed to the user if they are attempting to upload a file larger than 30MB over a non-Wi-Fi network. All functions must be deployed to the `asia-northeast1` region.  A new `transcriptionId` field has been added to the Lesson data structure to prevent duplicate processing.  A mechanism to handle large files gracefully, providing warnings to users when necessary, has been implemented. Robust error handling and logging for all API calls have been implemented. Retry mechanisms for failed API calls with exponential backoff have been implemented. The maximum file size for audio uploads is 100MB, and the maximum audio duration is 90 minutes. A warning will be displayed to the user if they are attempting to upload a file larger than 30MB over a non-Wi-Fi network. All functions must be deployed to the `asia-northeast1` region. The `sys.app_id` parameter is required. All functions should be deployed to the `asia-northeast1` region. All functions should be deployed to the asia-northeast1 region. The maximum file size for audio uploads is 100MB, and the maximum audio duration is 90 minutes. A warning will be displayed to the user if they are attempting to upload a file larger than 30MB over a non-Wi-Fi network. All functions must be deployed to the `asia-northeast1` region.  A new `lockAcquiredAt` field has been added to the Lesson data structure. A new `processAudioCustomFlow` function has been implemented to handle the custom flow: Whisper (with splitting) -> OpenAI (model unspecified) -> Gemini 1.5 Flash.  A new `processAudioV2` function has been implemented to dynamically select the appropriate processing flow based on user settings.  The `processAudioV2` function now calls `processAudioCustomFlow` or `processAudioDynamic` depending on the user's selected flow type.  A new `generateSummaryWithKnowledgeBase` function has been implemented to generate summaries using a knowledge base.  The knowledge base is now populated by an admin user via the `uploadKnowledge` function.  The `uploadKnowledge` function now includes an admin key for authentication. A new `adminListKnowledge`, `adminGetKnowledge`, `adminDeleteKnowledge`, and `getInstrumentTemplates` functions have been implemented for admin users to manage knowledge base entries.  The `getSummaryPromptByInstrument` function in `dify.ts` has been updated to use if statements instead of a switch statement to improve the accuracy of instrument matching.  The `getSummaryPromptForGemini` and `getTagsPromptForGemini` functions in `genkit.ts` have also been updated to use if statements for improved instrument matching. The `dify.ts` file and related functions have been removed from the project. The system now uses only the `genkit.ts` module for summary and tag generation. The `generateSummaryFromTranscriptionV2` function now uses `generateSummaryAndTags` for summary and tag generation. A new `generateSummaryWithKnowledge` function has been implemented to generate summaries using a knowledge base. The `generateSummaryWithKnowledgeBase` function now uses a knowledge base to generate summaries and tags.  A new `processAudioFileV2` function has been implemented to handle the audio file processing. A new `generateSummaryFromTranscriptionV2` function has been implemented to handle summary and tag generation.  The `processAudioV2` function now uses the `processAudioCustomFlow` function for the custom flow. The `processAudioCustomFlow` function now uses a knowledge base for summary generation. A new `adminListKnowledge`, `adminGetKnowledge`, `adminDeleteKnowledge`, and `getInstrumentTemplates` functions have been implemented for admin users to manage knowledge base entries.  The `getSummaryPromptByInstrument` function now uses if statements for improved instrument matching. The `getSummaryPromptForGemini` and `getTagsPromptForGemini` functions now use if statements for improved instrument matching. The `generateSummaryFromTranscriptionV2` function now uses `generateSummaryWithKnowledgeBase` if the knowledge base is enabled.  Tags are now generated as three comma-separated words.


## CODE STYLE

Maintain consistent code style throughout the project.  Use TypeScript for type safety and maintainability. Adhere to standard TypeScript naming conventions.

## FOLDER ORGANIZATION

The project follows a feature-based folder structure.  All components, services, and hooks related to a specific feature are organized within their respective folders under `app/features`.  Assets are stored in `app/assets`.  A new admin section has been added to handle the knowledge base management.

## TECH STACK

- React Native
- TypeScript
- Firebase (Firestore, Storage, Functions)
- OpenAI Whisper API
- Google Gemini API
- fluent-ffmpeg
- @ffmpeg-installer/ffmpeg
- fs-extra
- form-data
- @types/fluent-ffmpeg
- @types/fs-extra
- @types/form-data
- @react-native-community/netinfo
- @google/generative-ai


## PROJECT-SPECIFIC STANDARDS

- All audio files must be in MP3, WAV, or M4A format.
- Maximum audio file size: 100MB
- Maximum audio duration: 90 minutes
- All functions must be deployed to the `asia-northeast1` region.
- A warning will be displayed to the user if they are attempting to upload a file larger than 30MB over a non-Wi-Fi network.
- Lesson data includes `instrument`, `summary`, `tags`, `summaryRequired`, `summaryInProgress`, `transcriptionCompleteTime`, `transcriptionId`, `processingId`, and `lockAcquiredAt` fields.  `instrument` is populated from user profile.
- The `generateSummaryFromTranscriptionV2` function will only generate a summary if the `summaryRequired` field is `true` and the lesson's status is `transcribed`.
- The `processAudioCustomFlow` function uses Whisper for transcription (with audio splitting), OpenAI for summarization, and Gemini 1.5 Flash for tag generation and utilizes a knowledge base for improved summarization accuracy.
- The `processAudioV2` function dynamically chooses between the custom flow and the standard flow based on user settings.
- The `generateSummaryWithKnowledgeBase` function utilizes a knowledge base for improved summarization accuracy. The knowledge base is managed by admin users.
- The summary prompt is now: "{文字起こし}は{instrument}のレッスンの文字起こしデータです。この内容を、セクションごとに整理し、指摘内容・課題・練習アドバイスを簡潔にまとめてください。専門用語や基礎知識については{ナレッジ}を参考にして回答してください。【要件】- レッスンの内容をセクション単位（例：基礎練習、エチュード、曲名ごと）で分けて要約してください。- 各セクションで「指摘内容」「今後の課題」「練習アドバイス」の3つを明確に分類してください。- 雑談や無関係な話題は省き、重要な部分に焦点を当ててください。- ユーザーがわかりやすく、見やすく "復習" できるように出力してください- 各セクション400字程度にまとめてください【フォーマット（例）】■ セクション1：基礎練習（ロングトーン・スケール）1. 指摘内容：2. 今後の課題：3. 練習アドバイス：---■ セクション2：エチュード（例：○○教本 第3番）1. 指摘内容：2. 今後の課題：3. 練習アドバイス：---■ セクション3：曲（曲名：クラリネット協奏曲 第1楽章）1. 指摘内容：2. 今後の課題：3. 練習アドバイス：---"
- Tags are generated as three comma-separated words.


## WORKFLOW & RELEASE RULES

- Follow the standard Gitflow branching model.
- Create pull requests for all code changes.
- Code reviews are mandatory before merging any pull request.
- All deployments should be done through Firebase CLI.  All functions should be deployed to the `asia-northeast1` region.

## REFERENCE EXAMPLES

- Examples of using the OpenAI Whisper API and Google Gemini API should be documented in the project's wiki.

## PROJECT DOCUMENTATION & CONTEXT SYSTEM

- Maintain up-to-date documentation using Markdown format.
- Version updates will be noted in the relevant sections.
- Use a consistent naming convention for all files and folders.  All functions should be deployed to the `asia-northeast1` region.

## DEBUGGING

- Use Firebase console for debugging Cloud Functions.
- Use browser's DevTools console for debugging frontend API calls.
- Implement robust logging for all API calls.

## FINAL DOs AND DON'Ts

- **DO** use TypeScript for all new code.
- **DO** write unit tests for all new features.
- **DO** use Firebase Functions for backend logic.
- **DO** document all API calls and their parameters.
- **DO** handle errors gracefully and provide informative error messages to users.
- **DON'T** commit any unnecessary files to the repository.
- **DON'T** hardcode API keys or sensitive information in the code.
- **DON'T** use deprecated libraries or APIs.
- **DON'T** introduce breaking changes without proper communication and testing.
- The maximum file size for audio uploads is 100MB, and the maximum audio duration is 90 minutes. A warning will be displayed to the user if they are attempting to upload a file larger than 30MB over a non-Wi-Fi network.  All functions must be deployed to the `asia-northeast1` region.